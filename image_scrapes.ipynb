{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bea9a5d-a2dc-4675-968c-32a92d86d6b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /Users/yk6863/anaconda3/lib/python3.10/site-packages (2.31.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/yk6863/anaconda3/lib/python3.10/site-packages (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/yk6863/anaconda3/lib/python3.10/site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/yk6863/anaconda3/lib/python3.10/site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/yk6863/anaconda3/lib/python3.10/site-packages (from requests) (2024.2.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/yk6863/anaconda3/lib/python3.10/site-packages (from requests) (2.1.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/yk6863/anaconda3/lib/python3.10/site-packages (from beautifulsoup4) (2.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d05ed86-c722-41f0-8e38-32b8d7d2288c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/yk6863/anaconda3/lib/python3.10/site-packages (2.2.1)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /Users/yk6863/anaconda3/lib/python3.10/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/yk6863/anaconda3/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/yk6863/anaconda3/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/yk6863/anaconda3/lib/python3.10/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/yk6863/anaconda3/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7f97cf3-0519-4d1f-9552-350f433bcf4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.1.2-py2.py3-none-any.whl (249 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.0/250.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting et-xmlfile\n",
      "  Downloading et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-1.1.0 openpyxl-3.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3084d58f-4437-45ff-9ce9-5994cb0bcb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "urls = pd.read_excel('memestotal_data_urls_auto.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0e94842-cdc2-46a5-aa5c-28d35baa5994",
   "metadata": {},
   "outputs": [],
   "source": [
    "#urls = urls.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cc32502f-aa18-4cb9-9581-6bc03fbf0f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_list = urls.URL.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "256a492e-2d85-4f0f-9c45-31c5326c2500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['https://www.facebook.com/beingliberal.org/posts/10155979361361275',\n",
       "       'https://www.facebook.com/beingliberal.org/posts/10155973810706275',\n",
       "       'https://www.facebook.com/beingliberal.org/posts/10155971043486275',\n",
       "       ...,\n",
       "       'https://www.facebook.com/PeopleForBernie/posts/1840812859472253',\n",
       "       'https://www.facebook.com/OccupyDemocrats/posts/1223031201123265',\n",
       "       'https://www.facebook.com/beingliberal.org/posts/10153953903511275'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "97bd1516-a143-461c-b206-32bcf3eb36ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Directory where you want to save the images\n",
    "save_dir = '/Users/yk6863/Downloads/memes2'\n",
    "\n",
    "# Make sure the save directory exists\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1b7433-37f6-4e20-981d-24b9f8d519a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n",
      "Images downloaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import time\n",
    "\n",
    "soup_list = []\n",
    "for url in urls_list:\n",
    "    \n",
    "    # Send a HTTP request to the URL\n",
    "    response = requests.get(url)\n",
    "    # Read soup and find related tag\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    time.sleep(5)\n",
    "    \n",
    "    # Find all image content in the soup \n",
    "    img_tags = soup.find_all('meta')\n",
    "\n",
    "    # Loop through all found img content\n",
    "    for img in img_tags:\n",
    "    \n",
    "        # Get the source attribute of the img \n",
    "        img_url = img.get('content')\n",
    "        \n",
    "        # Complete the img_url if it's relative; be specific about the content names\n",
    "        if img_url.startswith(('http:', 'https://scontent')):\n",
    "            image_name = url.split('/')[-3] + '_' + url.split('/')[-1] + str('.jpeg')\n",
    "            filename = os.path.join(save_dir, image_name)\n",
    "          \n",
    "            # Send a request to download the image\n",
    "            with requests.get(img_url, stream=True) as r:\n",
    "                # Write the image to a file\n",
    "                with open(filename, 'wb') as f:\n",
    "                    for chunk in r.iter_content(chunk_size=8192):\n",
    "                        f.write(chunk)\n",
    "    print(\"Images downloaded successfully.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8755719a-b9f7-4604-ac5f-196fd70c47f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
